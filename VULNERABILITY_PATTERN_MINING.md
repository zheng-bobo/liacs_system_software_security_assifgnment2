# 漏洞模式挖掘（Vulnerability Pattern Mining）流程文档

## 概述

本文档描述从 MoreFixes 数据库中提取和识别重复漏洞代码模式的完整流程。该流程结合多种代码表示方法和相似度特征，自动生成可用于 GitHub 搜索的漏洞模式记录。

**主程序**: `vulnerability_pattern_miner.py`

## 完整流程

### Step 1: 数据提取（Data Extraction）

从 MoreFixes 数据库中提取高质量的漏洞修复样本。

**函数**: `extract_java_vulnerable_code()`  
**位置**: `vulnerability_pattern_miner.py`

**筛选条件**:
- `fixes.score >= 65`（高质量修复样本，准确率约 95%+）
- `file_change.diff IS NOT NULL`（要求有代码差异）
- `commits.merge = FALSE`（排除 merge commit，默认）
- `file_change.programming_language`（支持多语言，默认 Java）

**提取字段**:
- `cve_id`: CVE 编号
- `hash`: Commit hash
- `repo_url`: 仓库 URL
- `filename`: 文件名
- `code_before`: **漏洞前的代码**（pre-fix hunk，3-8 行上下文）
- `code_after`: 修复后的代码
- `diff`: 代码差异
- `score`: 修复质量分数

**输出**: `output/extract_java_vulnerable_code.csv`

---

### Step 2: 代码标准化与相似性匹配（Code Normalization & Similarity Matching）

对每个漏洞代码（`code_before`）进行多层次标准化处理。

**类**: `CodeSimilarityMatcher`  
**位置**: `code_similarity_matcher.py`  
**方法**: `compute_all_representations(code, language)`

#### 2.1 原始代码（Raw Text）

**方法**: `raw_text`（在 `compute_all_representations()` 中返回）

- **用途**: 保留原始代码，用于对照和人工检查
- **处理**: 直接返回原始代码，不做任何修改

#### 2.2 空白字符标准化（Whitespace Normalization）

**方法**: `extract_whitespace_normalized(code, preserve_newlines=False)`

- **用途**: 去除缩进、统一空格，提高文本一致性
- **处理流程**:
  1. 去除所有行首空白字符
  2. 去除空行
  3. 统一空格：多个连续空格替换为单个空格
  4. 根据 `preserve_newlines` 参数决定是否保留换行符

#### 2.3 变量名标准化（Identifier Normalization）

**方法**: `extract_identifier_normalized(code, language)`

- **用途**: 将变量名、方法名、类名替换为统一占位符，使不同项目中结构相同的代码能被识别
- **处理流程**:
  1. 先进行空白字符标准化（保留换行）
  2. 使用 AST parser（Java）或正则表达式进行标识符归一化
  3. 替换规则:
     - 变量名 → `VAR1`, `VAR2`, `VAR3`...
     - 方法名 → `FUNC1`, `FUNC2`, `FUNC3`...
     - 类名 → `CLASS1`, `CLASS2`, `CLASS3`...
     - 数字字面量 → `NUM`
     - 字符串字面量 → `STR`

**示例**:
```java
// 原始代码
String urlParam = request.getParameter("url");
File file = new File(path);

// 标准化后
VAR1 = VAR2.getParameter(STR);
VAR3 = new VAR4(VAR5);
```

#### 2.4 Token 化 → Token Shingles

**方法**: `extract_token_shingles(code, language)`

- **用途**: 用于文本相似度匹配（MinHash/LSH）
- **处理流程**:
  1. 原始代码 → 空白字符标准化
  2. → 变量名标准化（VAR1, VAR2...）
  3. → Token 化（按空白字符和标点符号分割）
  4. → 生成固定长度的 shingles（默认 5 个 token）

**示例**:
```
Tokens: ["VAR1", "=", "VAR2", ".", "getParameter", "(", "STR", ")"]
Shingles (size=5): 
  - "VAR1 = VAR2 . getParameter"
  - "= VAR2 . getParameter ("
  - "VAR2 . getParameter ( STR"
  ...
```

#### 2.5 AST 解析 → AST JSON

**方法**: `extract_ast_json(code, language)`（内部使用 `_ast_to_json()`）

- **用途**: 将代码解析为 AST，并转换为 JSON 格式
- **处理流程**:
  1. 原始代码 → 空白字符标准化（保留换行）
  2. → AST 解析（使用 javalang parser）
  3. → AST 转换为 JSON 字典
  4. → JSON 字符串化（用于生成哈希）

**AST JSON 结构**:
```json
{
  "type": "CompilationUnit",
  "package": {...},
  "types": [
    {
      "type": "ClassDeclaration",
      "name": "CLASS1",
      "methods": [...]
    }
  ]
}
```

#### 2.6 AST 子树哈希（AST Subtree Hash）

**方法**: `extract_ast_subtree_hash(code, language)`

- **用途**: 用于结构相似性匹配（最稳定的方法）
- **处理流程**:
  1. 原始代码 → 空白字符标准化（保留换行）
  2. → AST 解析 → AST JSON
  3. → JSON 字符串化（`sort_keys=True`）
  4. → SHA256 哈希（取前 16 位）

**特点**: 
- 最稳定的匹配方法
- 不受变量名、格式影响
- 只关注代码结构

#### 2.7 关键函数 Tokens（Keyword Tokens）

**方法**: `extract_keyword_tokens(code, language)`

- **用途**: 用于基础分组和 GitHub 搜索查询
- **提取内容**:
  - Java 关键字（if, for, while, try, catch, return 等）
  - 方法调用名（如 `getParameter`, `setHeader`）
  - 类名（首字母大写的标识符）
  - 常见 API 调用

**示例**:
```java
// 代码
String urlParam = request.getParameter("url");
response.setHeader("Cache-Control", "private");

// 提取的 keywords
{"getParameter", "setHeader", "String", "request", "response", "if", "try"}
```

#### 2.8 自动生成正则表达式（Regex Pattern）

**方法**: `extract_regex_candidate(code, language)`

- **用途**: 用于精确搜索
- **处理流程**:
  1. 先进行变量名标准化
  2. 将 `VAR1`, `VAR2`, `FUNC1` 等替换为 `(\w+)` 通配符
  3. 转义特殊字符，保留通配符

**示例**:
```
标准化文本: VAR1 = VAR2.getParameter(STR)
正则表达式: (\w+) = (\w+)\.getParameter\((\w+)\)
```

---

### Step 3: 模式聚类（Pattern Clustering）

结合多种特征进行相似度计算和聚类。

**方法**: `find_similar_fixes()`  
**位置**: `code_similarity_matcher.py`

#### 3.1 多特征相似度计算

**方法**: `compute_multi_feature_similarity(repr1, repr2)`

**特征权重**:
| 特征 | 权重 | 用途 |
|------|------|------|
| AST subtree hash | 0.4 | 结构匹配（最稳定） |
| Token shingles | 0.3 | 文本近似代码 |
| Keywords | 0.2 | 基础分组 |
| normalized_text | 0.1 | 人工检查 |

**相似度计算**:
```python
combined_similarity = (
    ast_hash_similarity * 0.4 +
    token_shingles_similarity * 0.3 +
    keywords_similarity * 0.2 +
    normalized_text_similarity * 0.1
)
```

#### 3.2 预分组优化（可选）

**参数**: `use_keyword_grouping=True`

- 使用 `keyword_tokens` 进行预分组
- 只在同一 keyword 组内进行比较
- 大幅减少比较次数，提高效率

#### 3.3 聚类分组

**分组策略**:
1. 优先使用 `ast_subtree_hash` 作为分组键（最稳定）
2. 如果没有 AST hash，使用 `normalized_text` 的前 100 字符
3. 至少需要 2 个相似样本才能形成模式

**输出**: 
- 相似漏洞对 DataFrame（包含相似度分数）
- 模式记录 DataFrame（Pattern Records）

---

### Step 4: 模式记录生成（Pattern Record Generation）

为每个相似模式组创建模式记录。

**方法**: `create_pattern_records()`  
**位置**: `code_similarity_matcher.py`

**模式记录字段**:

| 字段 | 说明 | 示例 |
|------|------|------|
| `pattern_id` | 模式 ID | `p001` |
| `language` | 编程语言 | `java` |
| `normalized_pattern_text` | 标准化模式文本 | `VAR1 = VAR2.getParameter(STR)` |
| `keyword_tokens` | 关键字 tokens 列表 | `["getParameter", "setHeader", "path.join"]` |
| `regex` | 正则表达式模式 | `(\w+) = (\w+)\.getParameter\((\w+)\)` |
| `ast_hash` | AST 子树哈希值 | `98af1234567890ab` |
| `example_cves` | 示例 CVE 列表 | `["CVE-2021-xxxx", "CVE-2022-yyyy"]` |
| `example_snippet` | 代表漏洞代码片段 | `String urlParam = request.getParameter("url");` |
| `pattern_count` | 该模式出现的次数 | `5` |

**输出**: `output/pattern_records_top{n}.csv`

---

### Step 5: GitHub 查询生成（Query Generation）

为每个模式生成 2-4 条 GitHub 搜索查询。

**类**: `GitHubQueryGenerator`  
**位置**: `github_query_generator.py`  
**方法**: `generate_github_queries(pattern_records_df, output_dir)`

#### 5.1 基础关键字查询（keyword_basic）

**Step 6.1**: 使用模式中的关键函数和 API 生成基础查询

```
"getParameter" "setHeader" "path.join" language:java
```

#### 5.2 TF-IDF 优化的查询（tfidf_refined）

**Step 6.2**: 使用 TF-IDF 提取中频危险 tokens

**方法**: `extract_tfidf_dangerous_tokens()`

- 从所有模式的 `keyword_tokens` 中提取中频危险 tokens
- 中频 = 既不是太常见（低 TF-IDF），也不是太罕见（高 TF-IDF）
- 默认范围: `min_tfidf=0.1, max_tfidf=0.7`

```
"getParameter" "setHeader" "url.parse" "process.cwd" language:java
```

#### 5.3 正则表达式查询（regex_based）

**Step 6.3**: 基于正则表达式模式生成查询

- 从正则表达式中提取关键标识符
- 过滤掉太短的关键字
- 生成关键字查询（GitHub 不支持完整正则表达式）

```
"getParameter" "url" "parse" language:java
```

#### 5.4 路径过滤查询（path_filter）

**Step 6.4**: 结合文件扩展名过滤

```
path:*.java "getParameter" "setHeader"
```

**查询生成规则**:
- 过滤掉太短（<3字符）或太通用的关键字
- 每个查询使用 2-3 个最重要的关键字
- 如果查询数量少于 2 个，添加综合关键字查询

**输出**: `output/github_queries.csv`

**字段**:
- `pattern_id`: 模式 ID
- `query_id`: 查询 ID（每个模式有多个查询）
- `query_type`: 查询类型（keyword_basic, tfidf_refined, regex_based, path_filter）
- `github_query`: GitHub 搜索查询语句
- `description`: 查询描述

---

## 完整工作流程

```
┌─────────────────────────────────────────────────────────────┐
│ Step 1: 数据提取                                            │
│ extract_java_vulnerable_code()                              │
│ - 从数据库提取高质量漏洞修复样本                            │
│ - 筛选条件: score >= 65, diff IS NOT NULL, merge = FALSE   │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 2: 代码标准化                                          │
│ CodeSimilarityMatcher.compute_all_representations()         │
│ - 原始代码 (Raw Text)                                       │
│ - 空白字符标准化 (Whitespace Normalization)                 │
│ - 变量名标准化 (Identifier Normalization)                   │
│ - Token Shingles                                            │
│ - AST JSON                                                  │
│ - AST Subtree Hash                                          │
│ - Keyword Tokens                                            │
│ - Regex Pattern                                             │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 3: 模式聚类                                            │
│ CodeSimilarityMatcher.find_similar_fixes()                  │
│ - 多特征相似度计算 (AST Hash, Token Shingles, Keywords)     │
│ - Keyword 预分组优化                                        │
│ - 聚类分组 (基于 AST Hash)                                   │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 4: 模式记录生成                                        │
│ CodeSimilarityMatcher.create_pattern_records()              │
│ - 为每个相似模式组创建 Pattern Record                       │
│ - 包含 pattern_id, normalized_text, keywords, regex 等     │
└─────────────────────────────────────────────────────────────┘
                          ↓
┌─────────────────────────────────────────────────────────────┐
│ Step 5: GitHub 查询生成                                     │
│ GitHubQueryGenerator.generate_github_queries()              │
│ - 基础关键字查询                                            │
│ - TF-IDF 优化的查询                                         │
│ - 正则表达式查询                                            │
│ - 路径过滤查询                                              │
└─────────────────────────────────────────────────────────────┘
```

## 使用方法

### 命令行使用

```bash
# 提取前 10 个最常见的漏洞模式
python vulnerability_pattern_miner.py --top-n 10 --min-score 65 --languages java

# 支持多语言
python vulnerability_pattern_miner.py --top-n 3 --languages java javascript python

# 包含 merge commit
python vulnerability_pattern_miner.py --top-n 3 --include-merge --languages java
```

### Python API 使用

```python
from vulnerability_pattern_miner import (
    DatabaseConnector,
    extract_java_vulnerable_code,
    process_recurring_patterns,
)
from github_query_generator import GitHubQueryGenerator
from pathlib import Path

# 1. 连接数据库
db_connector = DatabaseConnector()

# 2. 提取漏洞代码
vulnerable_code_df = extract_java_vulnerable_code(
    db_connector,
    min_score=65,
    exclude_merge_commits=True,
    programming_languages=["Java"],
    require_diff=True,
)

# 3. 识别重复模式并生成模式记录
pattern_records_df = process_recurring_patterns(
    vulnerable_code_df,
    top_n=10,
    similarity_method="exact",  # 默认使用 exact 方法
    similarity_threshold=0.5,
    use_keyword_grouping=True,
)

# 4. 生成 GitHub 查询
if len(pattern_records_df) > 0:
    query_generator = GitHubQueryGenerator()
    github_queries_df = query_generator.generate_github_queries(
        pattern_records_df,
        output_dir=Path("output")
    )
```

### 直接使用 CodeSimilarityMatcher

```python
from code_similarity_matcher import CodeSimilarityMatcher
import pandas as pd

# 创建匹配器
matcher = CodeSimilarityMatcher(shingle_size=5, use_ast=True)

# 准备数据
df = pd.DataFrame({
    'code_before': [...],
    'programming_language': ['java', ...],
    ...
})

# 查找相似模式
similar_fixes_df, pattern_records_df = matcher.find_similar_fixes(
    df,
    top_n=10,
    similarity_threshold=0.5,
    similarity_method="exact",  # 或使用 "combined" 获得更精确的匹配
    use_keyword_grouping=True,
    create_patterns=True,
)
```

## 输出文件

1. **`output/extract_java_vulnerable_code.csv`**
   - 提取的漏洞代码数据（排除 code_before 和 code_after 以减小文件大小）
   - 包含: cve_id, hash, repo_url, filename, score 等元数据

2. **`output/pattern_records_top{n}.csv`**
   - 模式记录（Pattern Records）
   - 包含所有模式字段: pattern_id, language, normalized_pattern_text, keyword_tokens, regex, ast_hash, example_cves, example_snippet, pattern_count

3. **`output/similar_fixes_top{n}.csv`**
   - 相似漏洞对数据
   - 包含相似度分数和代码预览: similarity, fix1_hash, fix2_hash, fix1_cve, fix2_cve, fix1_repo, fix2_repo, fix1_code_before, fix1_code_after, fix2_code_before, fix2_code_after

4. **`output/github_queries.csv`**
   - GitHub 搜索查询语句
   - 每个模式 2-4 条查询: pattern_id, query_id, query_type, github_query, description

## 技术细节

### 代码标准化流程

```
原始代码
  ↓
空白字符标准化（保留换行）
  ↓
变量名标准化（VAR1, VAR2...）
  ↓
Token 化
  ↓
生成 Shingles
```

### AST 处理流程

```
原始代码
  ↓
空白字符标准化（保留换行）
  ↓
AST 解析（javalang）
  ↓
AST → JSON
  ↓
JSON 字符串化（sort_keys=True）
  ↓
SHA256 哈希（前16位）
```

### 相似度计算流程

```
代码1 → 多特征表示
代码2 → 多特征表示
  ↓
计算各项相似度:
  - AST Hash 相似度（0.4 权重）
  - Token Shingles 相似度（0.3 权重）
  - Keywords 相似度（0.2 权重）
  - Normalized Text 相似度（0.1 权重）
  ↓
加权综合相似度
```

## 性能优化

1. **Keyword 预分组**: 使用 `use_keyword_grouping=True` 可以大幅减少比较次数
2. **AST Hash 优先**: 使用 AST hash 作为主要分组键，避免重复计算
3. **批量处理**: 支持 `top_n` 参数限制返回的模式数量

## 注意事项

1. **AST 解析**: 需要安装 `javalang` 库，如果不可用会回退到正则表达式方法
   ```bash
   pip install javalang
   ```

2. **内存使用**: 大量数据时注意内存占用，建议分批处理

3. **相似度阈值**: 根据实际需求调整 `similarity_threshold`，过低会产生太多误报，过高会漏掉相似项
   - 推荐范围: 0.4 - 0.7
   - 默认值: 0.5

4. **语言支持**: 
   - Java: 支持 AST 解析（需要 javalang）
   - 其他语言: 使用正则表达式方法进行标识符标准化

5. **相似度方法选择**:
   - `jaccard`: 基于 token shingles，适合一般相似度比较
   - `exact`: 精确匹配，适合查找完全相同的模式
   - `ast_hash`: AST 结构匹配，适合查找结构相同的模式
   - `combined`: 综合多特征，最准确（推荐）

## 示例输出

### Pattern Record 示例

```csv
pattern_id,language,normalized_pattern_text,keyword_tokens,regex,ast_hash,example_cves,example_snippet,pattern_count
p001,java,"VAR1 = VAR2.getParameter(STR);","getParameter,request,String","(\w+) = (\w+)\.getParameter\((\w+)\);","98af1234567890ab","CVE-2021-xxxx,CVE-2022-yyyy","String urlParam = request.getParameter(\"url\");",5
```

### GitHub Query 示例

```csv
pattern_id,query_id,query_type,github_query,description
p001,p001_q01,keyword_basic,"getParameter" "request" "String" language:java,Step 6.1 基础 Keyword 搜索: getParameter, request, String
p001,p001_q02,tfidf_refined,"getParameter" "setHeader" "url.parse" language:java,Step 6.2 TF-IDF 中频危险 Tokens: getParameter, setHeader, url.parse
p001,p001_q03,regex_based,"getParameter" "url" "parse" language:java,Step 6.3 正则搜索（基于正则模式）: getParameter, url, parse
p001,p001_q04,path_filter,path:*.java "getParameter" "request",Step 6.4 路径过滤: *.java, getParameter, request
```

## 相关文件

- `vulnerability_pattern_miner.py`: 主程序文件
- `code_similarity_matcher.py`: 代码相似性匹配模块
- `github_query_generator.py`: GitHub 查询生成模块
- `SIMILARITY_MATCHER_README.md`: 相似性匹配器详细文档
- `DATABASE_TABLES_EXPLANATION.md`: 数据库表结构说明
- `README.md`: 项目总体说明
